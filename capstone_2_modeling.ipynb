{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35cc0851-bacb-4f97-81f4-ff129c817c39",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The goal of this project is to determine the factors that directly contribute to student success for this online program. Previous EDA showed that the distributions of numeric data did not differ between passing and failing students. Since there are both continuous and categorical values to predict the student outcome, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da58ad09-d042-4816-9afd-dba404e2dca4",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f40eac41-1ac0-4f46-a2d4-9d991567d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "from subprocess import call\n",
    "from io import StringIO\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "from scipy import stats, optimize, spatial\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.colors\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "import pydotplus\n",
    "\n",
    "# Modeling\n",
    "from sklearn import datasets, svm, decomposition\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesRegressor, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.cluster import KMeans, AffinityPropagation, SpectralClustering, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, Normalizer, RobustScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, log_loss\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36141cd2-40a0-427e-b2a9-bb173fba93c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading statistical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82877a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
    "    n = len(data)\n",
    "    x = np.sort(data)\n",
    "    y = np.arange(1, n + 1) / n\n",
    "    return x, y\n",
    "\n",
    "def pearson_r(x , y):\n",
    "    \"\"\"Compute Pearson correlation coefficient between two arrays.\"\"\"\n",
    "    corr_mat = np.corrcoef(x, y)\n",
    "    return corr_mat[0, 1]\n",
    "\n",
    "def bootstrap_replicate_1d(data, func):\n",
    "    \"\"\"Generate bootstrap replicate of 1D data.\"\"\"\n",
    "    bs_sample = np.random.choice(data, len(data))\n",
    "    return func(bs_sample)\n",
    "\n",
    "def draw_bs_reps(data, func, size = 1):\n",
    "    \"\"\"Draw bootstrap replicates.\"\"\"\n",
    "    bs_replicates = np.empty(size)\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = bootstrap_replicate_1d(data, func)\n",
    "    return bs_replicates\n",
    "\n",
    "def draw_bs_pairs_linreg(x, y, size = 1):\n",
    "    \"\"\"perform pairs bootstrap for linear regression\"\"\"\n",
    "    inds = np.arange(len(x))\n",
    "    bs_slope_reps = np.empty(size)\n",
    "    bs_intercept_reps = np.empty(size)\n",
    "    for i in range(size):\n",
    "        bs_inds = np.random.choice(inds, size = len(inds))\n",
    "        bs_x, bs_y = x[bs_inds], y[bs_inds]\n",
    "        bs_slope_reps[i], bs_intercept_reps[i] = np.polyfit(bs_x, bs_y, 1)\n",
    "    return bs_slope_reps, bs_intercept_reps\n",
    "\n",
    "def draw_bs_pairs(x, y, func, size = 1):\n",
    "    \"\"\"Perform pairs bootstrap for a single statistic.\"\"\"\n",
    "    inds = np.arange(len(x))\n",
    "    bs_replicates = np.empty(size)\n",
    "    for i in range(size):\n",
    "        bs_inds = np.random.choice(inds, size = len(inds))\n",
    "        bs_x, bs_y = x[bs_inds], y[bs_inds]\n",
    "        bs_replicates[i] = func(bs_x, bs_y)\n",
    "    return bs_replicates\n",
    "\n",
    "def permutation_sample(data1, data2):\n",
    "    \"\"\"Generate a permutation sample from two data sets.\"\"\"\n",
    "    data = np.concatenate((data1, data2))\n",
    "    permuted_data = np.random.permutation(data)\n",
    "    perm_sample_1 = permuted_data[:len(data1)]\n",
    "    perm_sample_2 = permuted_data[len(data1):]\n",
    "    return perm_sample_1, perm_sample_2\n",
    "\n",
    "def draw_perm_reps(data_1, data_2, func, size=1):\n",
    "    \"\"\"Generate multiple permutation replicates.\"\"\"\n",
    "    perm_replicates = np.empty(size)\n",
    "    for i in range(size):\n",
    "        perm_sample_1, perm_sample_2 = permutation_sample(data_1, data_2)\n",
    "        perm_replicates[i] = func(perm_sample_1, perm_sample_2)\n",
    "    return perm_replicates\n",
    "\n",
    "def diff_of_means(data_1, data_2):\n",
    "    \"\"\"Difference in means of two arrays.\"\"\"\n",
    "    diff = np.mean(data_1) - np.mean(data_2)\n",
    "    return diff\n",
    "\n",
    "def diff_frac(data_A, data_b):\n",
    "    frac_A = np.sum(data_A) / len(data_A)\n",
    "    frac_B = np.sum(data_B) / len(data_B)\n",
    "    return frac_B - frac_A\n",
    "\n",
    "def rmse(pred, obs):\n",
    "    return np.sqrt(((pred - obs) ** 2).mean())\n",
    "\n",
    "def mse(pred, obs):\n",
    "    return ((pred - obs) ** 2).mean()\n",
    "\n",
    "def bon_correct(alpha, n):\n",
    "    return (alpha/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4be534-1802-42e6-8b81-6b833906c39b",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223ee967-c5ff-48a6-af7e-5ceaa8caacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('capstone_2_modeling_v2.csv')\n",
    "with open('region_map.pkl', 'rb') as f:\n",
    "    region_map = pickle.load(f)\n",
    "\n",
    "with open('activity_map.pkl', 'rb') as file:\n",
    "    activity_map = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e80d90-1d63-4faa-9a33-3fd1abba902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2552e0-9a72-4423-b00d-2957fde5b096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>disability</th>\n",
       "      <th>age_band</th>\n",
       "      <th>region</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>date_registration</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>final_result</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>mean_assessment_length</th>\n",
       "      <th>max_assessment_length</th>\n",
       "      <th>mean_active</th>\n",
       "      <th>total_active</th>\n",
       "      <th>mean_clicks</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2412002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5686</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-38</td>\n",
       "      <td>0</td>\n",
       "      <td>Distinction</td>\n",
       "      <td>90</td>\n",
       "      <td>9783</td>\n",
       "      <td>84.25</td>\n",
       "      <td>63.625</td>\n",
       "      <td>171</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2412002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5686</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-38</td>\n",
       "      <td>0</td>\n",
       "      <td>Distinction</td>\n",
       "      <td>90</td>\n",
       "      <td>15664</td>\n",
       "      <td>84.25</td>\n",
       "      <td>63.625</td>\n",
       "      <td>171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2412002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5686</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-38</td>\n",
       "      <td>0</td>\n",
       "      <td>Distinction</td>\n",
       "      <td>90</td>\n",
       "      <td>11403</td>\n",
       "      <td>84.25</td>\n",
       "      <td>63.625</td>\n",
       "      <td>171</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2412002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5686</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-38</td>\n",
       "      <td>0</td>\n",
       "      <td>Distinction</td>\n",
       "      <td>90</td>\n",
       "      <td>10272</td>\n",
       "      <td>84.25</td>\n",
       "      <td>63.625</td>\n",
       "      <td>171</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2412002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5686</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-38</td>\n",
       "      <td>0</td>\n",
       "      <td>Distinction</td>\n",
       "      <td>90</td>\n",
       "      <td>5981</td>\n",
       "      <td>84.25</td>\n",
       "      <td>63.625</td>\n",
       "      <td>171</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_student  gender  disability  age_band  region  imd_band  \\\n",
       "0     2412002       0           0         2    5686         5   \n",
       "1     2412002       0           0         2    5686         5   \n",
       "2     2412002       0           0         2    5686         5   \n",
       "3     2412002       0           0         2    5686         5   \n",
       "4     2412002       0           0         2    5686         5   \n",
       "\n",
       "   highest_education  date_registration  num_of_prev_attempts final_result  \\\n",
       "0                  2                -38                     0  Distinction   \n",
       "1                  2                -38                     0  Distinction   \n",
       "2                  2                -38                     0  Distinction   \n",
       "3                  2                -38                     0  Distinction   \n",
       "4                  2                -38                     0  Distinction   \n",
       "\n",
       "   studied_credits  activity_type  mean_score  mean_assessment_length  \\\n",
       "0               90           9783       84.25                  63.625   \n",
       "1               90          15664       84.25                  63.625   \n",
       "2               90          11403       84.25                  63.625   \n",
       "3               90          10272       84.25                  63.625   \n",
       "4               90           5981       84.25                  63.625   \n",
       "\n",
       "   max_assessment_length  mean_active  total_active  mean_clicks  clicks  \n",
       "0                    171          4.0             4    11.000000      11  \n",
       "1                    171          1.0             3     5.333333      16  \n",
       "2                    171          3.0             3     6.000000       6  \n",
       "3                    171          2.5             5    11.500000      23  \n",
       "4                    171          2.0             2     3.000000       3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d040342b-6143-4612-9875-227ffc5b9076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72305 entries, 0 to 72304\n",
      "Data columns (total 19 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id_student              72305 non-null  int64  \n",
      " 1   gender                  72305 non-null  int64  \n",
      " 2   disability              72305 non-null  int64  \n",
      " 3   age_band                72305 non-null  int64  \n",
      " 4   region                  72305 non-null  int64  \n",
      " 5   imd_band                72305 non-null  int64  \n",
      " 6   highest_education       72305 non-null  int64  \n",
      " 7   date_registration       72305 non-null  int64  \n",
      " 8   num_of_prev_attempts    72305 non-null  int64  \n",
      " 9   final_result            72305 non-null  object \n",
      " 10  studied_credits         72305 non-null  int64  \n",
      " 11  activity_type           72305 non-null  int64  \n",
      " 12  mean_score              72305 non-null  float64\n",
      " 13  mean_assessment_length  72305 non-null  float64\n",
      " 14  max_assessment_length   72305 non-null  int64  \n",
      " 15  mean_active             72305 non-null  float64\n",
      " 16  total_active            72305 non-null  int64  \n",
      " 17  mean_clicks             72305 non-null  float64\n",
      " 18  clicks                  72305 non-null  int64  \n",
      "dtypes: float64(4), int64(14), object(1)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87bcfe53-e2f9-406d-8ec9-12ee63047914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>disability</th>\n",
       "      <th>age_band</th>\n",
       "      <th>region</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>date_registration</th>\n",
       "      <th>num_of_prev_attempts</th>\n",
       "      <th>studied_credits</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>mean_assessment_length</th>\n",
       "      <th>max_assessment_length</th>\n",
       "      <th>mean_active</th>\n",
       "      <th>total_active</th>\n",
       "      <th>mean_clicks</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.230500e+04</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.000000</td>\n",
       "      <td>72305.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.136373e+05</td>\n",
       "      <td>0.392158</td>\n",
       "      <td>0.080658</td>\n",
       "      <td>1.316838</td>\n",
       "      <td>6256.934251</td>\n",
       "      <td>4.503409</td>\n",
       "      <td>2.822184</td>\n",
       "      <td>-64.656649</td>\n",
       "      <td>0.139230</td>\n",
       "      <td>75.746836</td>\n",
       "      <td>9807.248696</td>\n",
       "      <td>75.507870</td>\n",
       "      <td>103.061030</td>\n",
       "      <td>164.890851</td>\n",
       "      <td>2.089066</td>\n",
       "      <td>7.119203</td>\n",
       "      <td>6.297755</td>\n",
       "      <td>23.47514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.685251e+05</td>\n",
       "      <td>0.488235</td>\n",
       "      <td>0.272312</td>\n",
       "      <td>0.483412</td>\n",
       "      <td>1767.818949</td>\n",
       "      <td>2.822728</td>\n",
       "      <td>0.734119</td>\n",
       "      <td>40.937335</td>\n",
       "      <td>0.439077</td>\n",
       "      <td>32.128242</td>\n",
       "      <td>4126.458900</td>\n",
       "      <td>14.974022</td>\n",
       "      <td>42.343092</td>\n",
       "      <td>59.488002</td>\n",
       "      <td>2.006748</td>\n",
       "      <td>13.171022</td>\n",
       "      <td>8.463833</td>\n",
       "      <td>51.89753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.516000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2035.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-172.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.001120e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4912.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-93.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7666.000000</td>\n",
       "      <td>67.560000</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.845670e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6262.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>10272.000000</td>\n",
       "      <td>78.222222</td>\n",
       "      <td>103.380952</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.348330e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7558.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>11403.000000</td>\n",
       "      <td>86.421053</td>\n",
       "      <td>127.906977</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.698535e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8989.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>15664.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>236.857143</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>42.909091</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>232.375000</td>\n",
       "      <td>1859.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_student        gender    disability      age_band        region  \\\n",
       "count  7.230500e+04  72305.000000  72305.000000  72305.000000  72305.000000   \n",
       "mean   7.136373e+05      0.392158      0.080658      1.316838   6256.934251   \n",
       "std    5.685251e+05      0.488235      0.272312      0.483412   1767.818949   \n",
       "min    6.516000e+03      0.000000      0.000000      1.000000   2035.000000   \n",
       "25%    5.001120e+05      0.000000      0.000000      1.000000   4912.000000   \n",
       "50%    5.845670e+05      0.000000      0.000000      1.000000   6262.000000   \n",
       "75%    6.348330e+05      1.000000      0.000000      2.000000   7558.000000   \n",
       "max    2.698535e+06      1.000000      1.000000      3.000000   8989.000000   \n",
       "\n",
       "           imd_band  highest_education  date_registration  \\\n",
       "count  72305.000000       72305.000000       72305.000000   \n",
       "mean       4.503409           2.822184         -64.656649   \n",
       "std        2.822728           0.734119          40.937335   \n",
       "min        0.000000           1.000000        -172.000000   \n",
       "25%        2.000000           2.000000         -93.000000   \n",
       "50%        4.000000           3.000000         -53.000000   \n",
       "75%        7.000000           3.000000         -29.000000   \n",
       "max        9.000000           5.000000         -10.000000   \n",
       "\n",
       "       num_of_prev_attempts  studied_credits  activity_type    mean_score  \\\n",
       "count          72305.000000     72305.000000   72305.000000  72305.000000   \n",
       "mean               0.139230        75.746836    9807.248696     75.507870   \n",
       "std                0.439077        32.128242    4126.458900     14.974022   \n",
       "min                0.000000        30.000000       2.000000      0.000000   \n",
       "25%                0.000000        60.000000    7666.000000     67.560000   \n",
       "50%                0.000000        60.000000   10272.000000     78.222222   \n",
       "75%                0.000000        90.000000   11403.000000     86.421053   \n",
       "max                6.000000       180.000000   15664.000000    100.000000   \n",
       "\n",
       "       mean_assessment_length  max_assessment_length   mean_active  \\\n",
       "count            72305.000000           72305.000000  72305.000000   \n",
       "mean               103.061030             164.890851      2.089066   \n",
       "std                 42.343092              59.488002      2.006748   \n",
       "min                 -6.000000              -6.000000      1.000000   \n",
       "25%                 76.923077             131.000000      1.000000   \n",
       "50%                103.380952             178.000000      1.250000   \n",
       "75%                127.906977             209.000000      2.500000   \n",
       "max                236.857143             243.000000     42.909091   \n",
       "\n",
       "       total_active   mean_clicks       clicks  \n",
       "count  72305.000000  72305.000000  72305.00000  \n",
       "mean       7.119203      6.297755     23.47514  \n",
       "std       13.171022      8.463833     51.89753  \n",
       "min        1.000000      1.000000      1.00000  \n",
       "25%        2.000000      2.000000      3.00000  \n",
       "50%        4.000000      3.400000      8.00000  \n",
       "75%        8.000000      7.000000     23.00000  \n",
       "max      472.000000    232.375000   1859.00000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "283c4429-710e-492e-a71d-ed8244240ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72305, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b57b4d-e137-46f1-9da9-095d158157b1",
   "metadata": {},
   "source": [
    "# Splitting the Data\n",
    "\n",
    "Now that the data has been encoded, it can now be split into its respective x and y variables. The 'final_result' feature was left untouched since it was the response variable to all the other features. For x data, 'id_student' will be dropped since it serves as more of a categorical variable.\n",
    "\n",
    "Since the data points were originally ordered by assessment and student, I will need to shuffle the train_test to make sure students at the bottom of the df do not unnecessarily get cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fd1d1f7-c3ee-4c5a-9d1a-22b63b3cf38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns = ['id_student', 'final_result'])\n",
    "y = df[['final_result']]\n",
    "\n",
    "features = x.columns.tolist()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 6022, stratify = y, test_size = 0.25, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8233e-4636-401c-b3ef-b73e1668caab",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    "Despite encoding, a few columns are still beyond a comparable scope of eachother. A StandardScaler will be applied to ensure that all values are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63b55c86-0c42-468b-91db-38cdb655fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "scaler_model = scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5dfdacb-a29d-48de-8f69-ef1426cc6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scale = scaler_model.transform(x_train)\n",
    "x_test_scale = scaler_model.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "118bf0c5-e449-4c4b-bd22-71ba1b478f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_k = StratifiedKFold(5)\n",
    "n_est_first = [2**i for i in range(7)]\n",
    "n_est_second = [int(x) for x in np.linspace(start = 100, stop = 1500, num = 15)]\n",
    "n_est = n_est_first + n_est_second\n",
    "n_iter = 200\n",
    "verb = 4 #Extremely long training times for hypertuning required me to make sure that progress was being made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201fcc35-8559-469e-8640-ba8e109ef1be",
   "metadata": {},
   "source": [
    "# Simple Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "550467b2-41ac-4bfd-94ce-4d729edcc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 90, num = 9)],\n",
    "    'min_samples_split': [x for x in np.linspace(0.01, 0.5, 10, endpoint = True)]\n",
    "}\n",
    "\n",
    "cv_dt = DecisionTreeClassifier(max_features = 'sqrt', random_state = 6022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "735cd5f2-0d53-4aa1-865b-28f683841cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:318: UserWarning: The total space of parameters 180 is smaller than n_iter=200. Running 180 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.01;, score=(train=0.661, test=0.654) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.01;, score=(train=0.657, test=0.653) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.01;, score=(train=0.652, test=0.643) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.01;, score=(train=0.653, test=0.643) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.01;, score=(train=0.654, test=0.650) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.06444444444444444;, score=(train=0.649, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.06444444444444444;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.639) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.06444444444444444;, score=(train=0.641, test=0.640) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.636) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.638) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, min_samples_split=0.5;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, min_samples_split=0.5;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, min_samples_split=0.5;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, min_samples_split=0.5;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, min_samples_split=0.5;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.01;, score=(train=0.661, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.01;, score=(train=0.665, test=0.651) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.01;, score=(train=0.656, test=0.641) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.01;, score=(train=0.662, test=0.648) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.01;, score=(train=0.660, test=0.642) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.06444444444444444;, score=(train=0.649, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.06444444444444444;, score=(train=0.639, test=0.643) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.638) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.06444444444444444;, score=(train=0.641, test=0.640) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.636) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.638) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=20, min_samples_split=0.5;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=20, min_samples_split=0.5;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=20, min_samples_split=0.5;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=20, min_samples_split=0.5;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=20, min_samples_split=0.5;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.01;, score=(train=0.661, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.01;, score=(train=0.665, test=0.651) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.01;, score=(train=0.656, test=0.641) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.01;, score=(train=0.662, test=0.648) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.01;, score=(train=0.660, test=0.642) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.06444444444444444;, score=(train=0.649, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.06444444444444444;, score=(train=0.639, test=0.643) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.638) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.06444444444444444;, score=(train=0.641, test=0.640) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.636) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.638) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=30, min_samples_split=0.5;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=30, min_samples_split=0.5;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=30, min_samples_split=0.5;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=30, min_samples_split=0.5;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=30, min_samples_split=0.5;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.01;, score=(train=0.661, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.01;, score=(train=0.665, test=0.651) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.01;, score=(train=0.656, test=0.641) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.01;, score=(train=0.662, test=0.648) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.01;, score=(train=0.660, test=0.642) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.06444444444444444;, score=(train=0.649, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.06444444444444444;, score=(train=0.639, test=0.643) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.638) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.06444444444444444;, score=(train=0.641, test=0.640) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.636) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.638) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, min_samples_split=0.5;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, min_samples_split=0.5;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, min_samples_split=0.5;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, min_samples_split=0.5;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, min_samples_split=0.5;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.01;, score=(train=0.661, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.01;, score=(train=0.665, test=0.651) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.01;, score=(train=0.656, test=0.641) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.01;, score=(train=0.662, test=0.648) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.01;, score=(train=0.660, test=0.642) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.06444444444444444;, score=(train=0.649, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.06444444444444444;, score=(train=0.639, test=0.643) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.638) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.06444444444444444;, score=(train=0.641, test=0.640) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.636) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.638) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=50, min_samples_split=0.5;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=50, min_samples_split=0.5;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=50, min_samples_split=0.5;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=50, min_samples_split=0.5;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=50, min_samples_split=0.5;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.01;, score=(train=0.661, test=0.650) total time=   0.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.01;, score=(train=0.665, test=0.651) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.01;, score=(train=0.656, test=0.641) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.01;, score=(train=0.662, test=0.648) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.01;, score=(train=0.660, test=0.642) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.06444444444444444;, score=(train=0.649, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.06444444444444444;, score=(train=0.639, test=0.643) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.638) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.06444444444444444;, score=(train=0.641, test=0.640) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.636) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.638) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=60, min_samples_split=0.5;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=60, min_samples_split=0.5;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=60, min_samples_split=0.5;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=60, min_samples_split=0.5;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=60, min_samples_split=0.5;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.01;, score=(train=0.661, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.01;, score=(train=0.665, test=0.651) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.01;, score=(train=0.656, test=0.641) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.01;, score=(train=0.662, test=0.648) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.01;, score=(train=0.660, test=0.642) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.06444444444444444;, score=(train=0.649, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.06444444444444444;, score=(train=0.639, test=0.643) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.638) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.06444444444444444;, score=(train=0.641, test=0.640) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.636) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.638) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.33666666666666667;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.33666666666666667;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.3911111111111111;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.3911111111111111;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.44555555555555554;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.44555555555555554;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=70, min_samples_split=0.5;, score=(train=0.632, test=0.632) total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=70, min_samples_split=0.5;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=70, min_samples_split=0.5;, score=(train=0.631, test=0.630) total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=70, min_samples_split=0.5;, score=(train=0.631, test=0.629) total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=70, min_samples_split=0.5;, score=(train=0.632, test=0.629) total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=80, min_samples_split=0.01;, score=(train=0.661, test=0.650) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=80, min_samples_split=0.01;, score=(train=0.665, test=0.651) total time=   0.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=80, min_samples_split=0.01;, score=(train=0.656, test=0.641) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=80, min_samples_split=0.01;, score=(train=0.662, test=0.648) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=80, min_samples_split=0.01;, score=(train=0.660, test=0.642) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=80, min_samples_split=0.06444444444444444;, score=(train=0.649, test=0.647) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=80, min_samples_split=0.06444444444444444;, score=(train=0.639, test=0.643) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=80, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.638) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=80, min_samples_split=0.06444444444444444;, score=(train=0.641, test=0.640) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=80, min_samples_split=0.06444444444444444;, score=(train=0.638, test=0.636) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=80, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=80, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.638) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=80, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=80, min_samples_split=0.11888888888888888;, score=(train=0.635, test=0.637) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=80, min_samples_split=0.11888888888888888;, score=(train=0.636, test=0.632) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=80, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=80, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.634) total time=   0.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=80, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=80, min_samples_split=0.17333333333333334;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=80, min_samples_split=0.17333333333333334;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=80, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=80, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.634) total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=80, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.630) total time=   0.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=80, min_samples_split=0.22777777777777777;, score=(train=0.631, test=0.629) total time=   0.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=80, min_samples_split=0.22777777777777777;, score=(train=0.632, test=0.629) total time=   0.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=80, min_samples_split=0.2822222222222222;, score=(train=0.632, test=0.632) total time=   0.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=80, min_samples_split=0.2822222222222222;, score=(train=0.631, test=0.634) total time=   0.1s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      2\u001b[0m dt_rand \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m      3\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m cv_dt,\n\u001b[0;32m      4\u001b[0m     param_distributions \u001b[38;5;241m=\u001b[39m dt_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6022\u001b[39m\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m dt_rand_cv \u001b[38;5;241m=\u001b[39m dt_rand\u001b[38;5;241m.\u001b[39mfit(x_train_scale, y_train)\n\u001b[0;32m     12\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     13\u001b[0m dt_cv_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1915\u001b[0m         ParameterSampler(\n\u001b[0;32m   1916\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1917\u001b[0m         )\n\u001b[0;32m   1918\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:922\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    920\u001b[0m     score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n\u001b[1;32m--> 922\u001b[0m         train_scores \u001b[38;5;241m=\u001b[39m _score(\n\u001b[0;32m    923\u001b[0m             estimator, X_train, y_train, scorer, score_params_train, error_score\n\u001b[0;32m    924\u001b[0m         )\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    927\u001b[0m     total_time \u001b[38;5;241m=\u001b[39m score_time \u001b[38;5;241m+\u001b[39m fit_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[0;32m    980\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 982\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, y_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:415\u001b[0m, in \u001b[0;36m_PassthroughScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    414\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39mscore(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:764\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X), sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:529\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;124;03m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    528\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 529\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m    530\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m    531\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:489\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    490\u001b[0m     X,\n\u001b[0;32m    491\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    492\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    493\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m    495\u001b[0m )\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    497\u001b[0m     X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc\n\u001b[0;32m    498\u001b[0m ):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:997\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    995\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 997\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1001\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:521\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    519\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 521\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "dt_rand = RandomizedSearchCV(\n",
    "    estimator = cv_dt,\n",
    "    param_distributions = dt_params,\n",
    "    cv = cv_k,\n",
    "    n_iter = n_iter,\n",
    "    verbose = verb,\n",
    "    return_train_score = True,\n",
    "    random_state = 6022\n",
    ")\n",
    "dt_rand_cv = dt_rand.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "dt_cv_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a891466-7410-4e44-90b5-7ada9f5a9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score:\" + str(dt_rand_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(dt_rand_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07064995-d04e-4b9f-9cf7-e467460ae9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(**dt_rand_cv.best_params_, max_features = 'sqrt', random_state = 6022)\n",
    "\n",
    "start_time = time.time()\n",
    "dt_model = dt.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "dt_fit_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "dt_pred = dt_model.predict(x_test_scale)\n",
    "end_time = time.time()\n",
    "dt_pred_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81f6535-c060-4a6f-bd8d-ae101c016964",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dt_cv_scores_test = cross_val_score(dt_model, x_test_scale, y_test, cv = cv_k, scoring = 'roc_auc')\n",
    "dt_cv_scores_train = cross_val_score(dt_model, x_train_scale, y_train, cv = cv_k, scoring = 'roc_auc')\n",
    "print(f'Training CV Score: {dt_cv_scores_train.mean()} +- {dt_cv_scores_train.std()}')\n",
    "print(f'Testing CV Score: {dt_cv_scores_test.mean()} +- {dt_cv_scores_test.std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907fbe5-c223-4a5d-8166-f512540af88a",
   "metadata": {},
   "source": [
    "Because of the heavy class imbalance, the models cannot be compared using cross-validation scores. The metrics obtained from the confusion matrix will be how the final model is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b1ca8-f4f7-41f3-a25a-0603891d8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_confusion = confusion_matrix(y_test, dt_pred, labels = dt_model.classes_)\n",
    "dt_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix = dt_confusion, display_labels = dt_model.classes_)\n",
    "dt_confusion_matrix.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35880e-4054-4d88-9964-beb2ae92fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b72146b-baab-4d5a-995a-34b63afe1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_imp = dt_model.feature_importances_\n",
    "dt_feat_imp_df = pd.DataFrame({'feature': features, 'importance': dt_imp})\n",
    "dt_sorted = dt_feat_imp_df.sort_values(by = 'importance', ascending = False)\n",
    "dt_feat_plot = sns.catplot(data = dt_sorted.head(20), kind = 'bar', x = 'feature', y = 'importance', height = 5, aspect = 2)\n",
    "dt_feat_plot = plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1631a0f-ed17-406b-b52a-6e5bfbdc1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV time: {dt_cv_time}')\n",
    "print(f'Fit time: {dt_fit_time}')\n",
    "print(f'Predict time: {dt_pred_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1253cca-5876-488f-a499-5052716f72e8",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': n_est,\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 90, num = 9)],\n",
    "    'min_samples_split': [x for x in np.linspace(0.01, 0.5, 10, endpoint = True)]\n",
    "}\n",
    "\n",
    "cv_rf = RandomForestClassifier(max_features = 'sqrt', n_jobs = 6, random_state = 6022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f13306",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "rf_rand = RandomizedSearchCV(\n",
    "    estimator = cv_rf,\n",
    "    param_distributions = rf_params,\n",
    "    cv = cv_k,\n",
    "    n_iter = n_iter,\n",
    "    verbose = verb,\n",
    "    return_train_score = True,\n",
    "    random_state = 6022\n",
    ")\n",
    "rf_rand_cv = rf_rand.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "rf_cv_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score:\" + str(rf_rand_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(rf_rand_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279157b1-cd55-4ba7-a084-ba9ada27d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(**rf_rand_cv.best_params_, max_features = 'sqrt', random_state = 6022)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_model = rf.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "rf_fit_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "rf_pred = rf_model.predict(x_test_scale)\n",
    "end_time = time.time()\n",
    "rf_pred_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846022ad-7f07-41c2-a9ec-e44edfa2c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_confusion = confusion_matrix(y_test, rf_pred, labels = rf_model.classes_)\n",
    "rf_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix = rf_confusion, display_labels = rf_model.classes_)\n",
    "rf_confusion_matrix.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717bc3f-ee8e-405e-81dc-f2ff75723259",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b7fd60-0883-4653-9aa9-6f0a3e421279",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_imp = rf_model.feature_importances_\n",
    "rf_feat_imp_df = pd.DataFrame({'feature': features, 'importance': rf_imp})\n",
    "rf_sorted = rf_feat_imp_df.sort_values(by = 'importance', ascending = False)\n",
    "rf_feat_plot = sns.catplot(data = rf_sorted.head(20), kind = 'bar', x = 'feature', y = 'importance', height = 5, aspect = 2)\n",
    "rf_feat_plot = plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da4fcd9-a217-4d67-b45b-5c83f1cb0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV time: {rf_cv_time}')\n",
    "print(f'Fit time: {rf_fit_time}')\n",
    "print(f'Predict time: {rf_pred_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c2ef3-3e6b-470c-ad86-67adc010d5dd",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d90e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_params = {\n",
    "    'n_neighbors': n_est_first,\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "cv_knn = KNeighborsClassifier(n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506cfae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "knn_rand = RandomizedSearchCV(\n",
    "    estimator = cv_knn,\n",
    "    param_distributions = knn_params,\n",
    "    cv = cv_k,\n",
    "    n_iter = n_iter,\n",
    "    verbose = verb,\n",
    "    return_train_score = True,\n",
    "    random_state = 6022\n",
    ")\n",
    "knn_rand_cv = knn_rand.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "knn_cv_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98302c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score:\" + str(knn_rand_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(knn_rand_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5999c3-8723-4612-8613-32098b82908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifer(**knn_rand_cv.best_params_, random_state = 6022)\n",
    "\n",
    "start_time = time.time()\n",
    "knn_model = knn.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "knn_fit_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "knn_pred = knn_model.predict(x_test_scale)\n",
    "end_time = time.time()\n",
    "knn_pred_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02668c86-8818-48c2-bda2-a93dcf33cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_confusion = confusion_matrix(y_test, knn_pred, labels = knn_model.classes_)\n",
    "knn_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix = knn_confusion, display_labels = knn_model.classes_)\n",
    "knn_confusion_matrix.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dacee8-5842-4798-ad8c-882681870f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f69ed0c-59de-4f38-aab5-49bc81b683b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imp = knn_model.feature_importances_\n",
    "knn_feat_imp_df = pd.DataFrame({'feature': features, 'importance': knn_imp})\n",
    "knn_sorted = knn_feat_imp_df.sort_values(by = 'importance', ascending = False)\n",
    "knn_feat_plot = sns.catplot(data = knn_sorted.head(20), kind = 'bar', x = 'feature', y = 'importance', height = 5, aspect = 2)\n",
    "knn_feat_plot = plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac89216-8dfe-41bf-9db5-0dcb6e1dfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV time: {knn_cv_time}')\n",
    "print(f'Fit time: {knn_fit_time}')\n",
    "print(f'Predict time: {knn_pred_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f00c291-3942-4b0c-a829-4ec0d89a68ea",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317baff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'None'],\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'],\n",
    "    'C': [0.001, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "cv_lr = LogisticRegression(n_jobs = 6, random_state = 6022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997a3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "lr_rand = RandomizedSearchCV(\n",
    "    estimator = cv_lr,\n",
    "    param_distributions = lr_params,\n",
    "    cv = cv_k,\n",
    "    n_iter = n_iter,\n",
    "    verbose = verb,\n",
    "    return_train_score = True,\n",
    "    random_state = 6022\n",
    ")\n",
    "lr_rand_cv = lr_rand.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "lr_cv_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score:\" + str(lr_rand_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(lr_rand_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63e6c5-3345-416d-9bba-7c130e595a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(**lr_rand_cv.best_params_, random_state = 6022)\n",
    "\n",
    "start_time = time.time()\n",
    "lr_model = lr.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "lr_fit_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "lr_pred = lr_model.predict(x_test_scale)\n",
    "end_time = time.time()\n",
    "lr_pred_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad7004-d1b8-4564-adb8-5334de162f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_confusion = confusion_matrix(y_test, lr_pred, labels = lr_model.classes_)\n",
    "lr_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix = lr_confusion, display_labels = lr_model.classes_)\n",
    "lr_confusion_matrix.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3edb2-52ba-4f0e-916e-e0a683bf140f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff49c1e-9ef2-479f-85f4-6dc9a8f92718",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_imp = lr_model.feature_importances_\n",
    "lr_feat_imp_df = pd.DataFrame({'feature': features, 'importance': lr_imp})\n",
    "lr_sorted = lr_feat_imp_df.sort_values(by = 'importance', ascending = False)\n",
    "lr_feat_plot = sns.catplot(data = lr_sorted.head(20), kind = 'bar', x = 'feature', y = 'importance', height = 5, aspect = 2)\n",
    "lr_feat_plot = plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6884ae-8b27-4ccf-bc47-9ff8d74e7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV time: {lr_cv_time}')\n",
    "print(f'Fit time: {lr_fit_time}')\n",
    "print(f'Predict time: {lr_pred_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9bf58e-b67e-4bbc-b217-bf322f765db6",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b62eea-564f-455a-8b6c-040af2a28e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params = {\n",
    "    'n_estimators': n_est_second,\n",
    "    'learning_rate': [0.1, 0.25, 0.5, 1],\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 90, num = 9)],\n",
    "    'max_features': ['log2', 'sqrt'],\n",
    "    'min_samples_split': [x for x in np.linspace(0.01, 0.5, 10, endpoint = True)]\n",
    "}\n",
    "\n",
    "cv_gb = GradientBoostingClassifier(random_state = 6022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "gb_rand = RandomizedSearchCV(\n",
    "    estimator = cv_gb,\n",
    "    param_distributions = gb_params,\n",
    "    cv = cv_k,\n",
    "    n_iter = n_iter,\n",
    "    verbose = verb,\n",
    "    return_train_score = True,\n",
    "    random_state = 6022\n",
    ")\n",
    "gb_rand_cv = gb_rand.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "gb_cv_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f1aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score:\" + str(gb_rand_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(gb_rand_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10234fe6-e79d-43c1-86b5-68ec3e94374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(**gb_rand_cv.best_params_, random_state = 6022)\n",
    "\n",
    "start_time = time.time()\n",
    "gb_model = gb.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "gb_fit_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "gb_pred = gb_model.predict(x_test_scale)\n",
    "end_time = time.time()\n",
    "gb_pred_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee5ae7b-cc3b-46b4-9284-ac0c3b7fa348",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_confusion = confusion_matrix(y_test, gb_pred, labels = gb_model.classes_)\n",
    "gb_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix = gb_confusion, display_labels = gb_model.classes_)\n",
    "gb_confusion_matrix.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5643e098-1d93-4142-9ada-b9d5956ab159",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, gb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed13037-a043-4a3b-8130-c0e2faac7512",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_imp = gb_model.feature_importances_\n",
    "gb_feat_imp_df = pd.DataFrame({'feature': features, 'importance': gb_imp})\n",
    "gb_sorted = gb_feat_imp_df.sort_values(by = 'importance', ascending = False)\n",
    "gb_feat_plot = sns.catplot(data = gb_sorted.head(20), kind = 'bar', x = 'feature', y = 'importance', height = 5, aspect = 2)\n",
    "gb_feat_plot = plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5232ac-ab26-4e94-891f-36da5ba73dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV time: {gb_cv_time}')\n",
    "print(f'Fit time: {gb_fit_time}')\n",
    "print(f'Predict time: {gb_pred_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c7d981-9150-4848-9d56-86728fd5deb0",
   "metadata": {},
   "source": [
    "# KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3589beb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_params = {\n",
    "    'init': ['k-means++', 'random'],\n",
    "    'max_iter': n_est\n",
    "}\n",
    "\n",
    "cv_km = KMeans(n_clusters = 4, random_state = 6022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f1c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "km_rand = RandomizedSearchCV(\n",
    "    estimator = cv_km,\n",
    "    param_distributions = km_params,\n",
    "    cv = cv_k,\n",
    "    n_iter = n_iter,\n",
    "    verbose = verb,\n",
    "    return_train_score = True,\n",
    "    random_state = 6022\n",
    ")\n",
    "km_rand_cv = km_rand.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "km_cv_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91cac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Score:\" + str(km_rand_cv.best_score_))\n",
    "print(\"Best Parameters: \" + str(km_rand_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf83abb-4a43-4355-a7af-a3c3b1388313",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(**km_rand_cv.best_params_, n_clusters = 4, random_state = 6022)\n",
    "\n",
    "start_time = time.time()\n",
    "km_model = km.fit(x_train_scale, y_train)\n",
    "end_time = time.time()\n",
    "km_fit_time = end_time - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "km_pred = km_model.predict(x_test_scale)\n",
    "end_time = time.time()\n",
    "km_pred_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8608a-c58c-41a2-bf98-b5a270aaec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_confusion = confusion_matrix(y_test, km_pred, labels = km_model.classes_)\n",
    "km_confusion_matrix = ConfusionMatrixDisplay(confusion_matrix = km_confusion, display_labels = km_model.classes_)\n",
    "km_confusion_matrix.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a37532c-90c9-4bf4-8519-932e9b01f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, km_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2798304-ed8f-4112-9872-7b416f6434dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_imp = km_model.feature_importances_\n",
    "km_feat_imp_df = pd.DataFrame({'feature': features, 'importance': km_imp})\n",
    "km_sorted = km_feat_imp_df.sort_values(by = 'importance', ascending = False)\n",
    "km_feat_plot = sns.catplot(data = km_sorted.head(20), kind = 'bar', x = 'feature', y = 'importance', height = 5, aspect = 2)\n",
    "km_feat_plot = plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6438ab-4240-4f68-923c-82a446f54f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'CV time: {km_cv_time}')\n",
    "print(f'Fit time: {km_fit_time}')\n",
    "print(f'Predict time: {km_pred_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
